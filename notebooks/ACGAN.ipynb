{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "> **University of Pisa** \\\n",
    "> **M.Sc. Computer Science, Artificial Intelligence** \\\n",
    "> **Continual learning 2022/23** \\\n",
    "> **Authors**\n",
    "* Andrea Iommi - a.iommi2@studenti.unipi.it\n",
    "\n",
    "# Memory Replay GANs\n",
    "# Learning to generate images from new categories without forgetting\n",
    "#### [(original paper)](https://proceedings.neurips.cc/paper/2018/hash/a57e8915461b83adefb011530b711704-Abstract.html)\n",
    "### Notebooks\n",
    "*   **Classical acGAN in offline settings**\n",
    "*   Classical acGAN in online settings\n",
    "*   acGAN with join retrain\n",
    "*   acGAN with replay alignment\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from Trainer import Trainer\n",
    "from Utils import custom_mnist\n",
    "from Plot_functions import generate_classes, plot_history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    num_classes=10,\n",
    "    img_size=32,\n",
    "    channels=1,\n",
    "    n_epochs=[1],\n",
    "    batch_size=64,\n",
    "    embedding=100, # latent dimension of embedding\n",
    "    lr_g=0.0002, # Learning rate for generator\n",
    "    lr_d=0.0002 # Learning rate for discriminator\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classical acGAN in offline settings (training)\n",
    "As a first step, we create a classical acGAN in offline setting, where all digits are learned at the same time.\n",
    "In this setting, we have only one experience that contains all digits."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiences = [[0,1,2,3,4,5,6,7,8,9]] # list of experiences\n",
    "exp_generator = custom_mnist(experiences = experiences)\n",
    "trainer = Trainer(config=config)\n",
    "history = trainer.fit_classic(experiences=exp_generator,create_gif=True)\n",
    "# we removed all training logs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loss functions and Accuracy\n",
    "\n",
    "The charts below represent the *loss function* for both Generator and Discriminator. Since the GAN architecture is based on Min-Max optimization, the loss functions are not smooth but irregular. Generally, finding an optimal parametrization is really hard for this kind of architecture. We relied on the original paper for the **learning rate** and **batch_size** (linked in above)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_history(history)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate the architecture\n",
    "\n",
    "As we can see, the model is able to generate quite well all digits.\n",
    "In the following figure, we have an example of results. We identify *t* as a conditional input and *gen* as the number of examples to generate."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generate_classes(trainer.generator, config[\"num_classes\"], rows=10, device=config[\"device\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
